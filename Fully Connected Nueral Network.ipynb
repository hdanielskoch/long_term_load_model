{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project='ebce-models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    -- 73MB\n",
    "    SELECT *\n",
    "    FROM `ebce-models.hdk_temp.weathersource_load_hourly_actuals`\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "load_features = query_job.to_dataframe()\n",
    "\n",
    "#Print dimensions\n",
    "display(f\"Load dimensions: {load_features.shape}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "load_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot number of customers, total system load vs datetime\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add trace for Total System Load\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=load_features['datetime'], \n",
    "    y=load_features['total_system_load'], \n",
    "    mode='lines', \n",
    "    name='Total System Load', \n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Add trace for Number of Customers\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=load_features['datetime'], \n",
    "    y=load_features['total_system_customers'], \n",
    "    mode='lines', \n",
    "    name='Number of Customers', \n",
    "    line=dict(color='green'),\n",
    "    yaxis='y2'  # Specify secondary y-axis\n",
    "))\n",
    "\n",
    "# Update layout for two y-axes\n",
    "fig.update_layout(\n",
    "    title='Number of Customers and Total System Load Over Time',\n",
    "    xaxis_title='Datetime',\n",
    "    yaxis=dict(\n",
    "        title='Total System Load',\n",
    "        titlefont=dict(color='blue'),\n",
    "        tickfont=dict(color='blue')\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Number of Customers',\n",
    "        titlefont=dict(color='green'),\n",
    "        tickfont=dict(color='green'),\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    legend=dict(x=0, y=1),\n",
    "    xaxis=dict(rangeslider=dict(visible=True)),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the one anomaly in 2023\n",
    "load_features[(load_features['datetime'] >= '2023-03-06 22:00:00') & (load_features['datetime'] <= '2023-03-07 00:00:00')][['datetime', 'total_system_load', 'total_system_customers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_features_tx = load_features.copy()\n",
    "load_features_tx  = load_features_tx[load_features_tx['datetime'] != '2023-03-06 23:00:00']\n",
    "print(f\"Load dimensions before transformation: {load_features.shape}\")\n",
    "print(f\"Load dimensions after transformation: {load_features_tx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns with data leakage\n",
    "load_features_tx.drop(columns=['load_cz1', 'load_cz2', 'load_cz3', 'load_cz4', 'load_cz5', 'load_cz6'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  \n",
    "null_counts = load_features_tx.isnull().sum()\n",
    "print(null_counts[null_counts > 0])\n",
    "pd.set_option('display.max_rows', 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Handling\n",
    "#Set number of customers to 0 when that territory has no data.\n",
    "cols_to_fill_zero = [\n",
    "    'customers_cz2', 'customers_cz4', 'customers_cz5', 'customers_cz6'\n",
    "]\n",
    "\n",
    "# Set specific columns to 0 where they have null values\n",
    "load_features_tx.loc[:, cols_to_fill_zero] = load_features_tx.loc[:, cols_to_fill_zero].fillna(0).copy()\n",
    "print(f\"Load dimensions before transformation: {load_features.shape}\")\n",
    "print(f\"Load dimensions after transformation: {load_features_tx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coonvert to Sunday = 0, Monday = 1, Tuesday = 2, Wednesday = 3, Thursday = 4, Friday = 5, Saturday = 6\n",
    "\n",
    "load_features_tx['day_of_week_mod'] = load_features_tx['datetime'].dt.weekday\n",
    "# load_features_tx['day_of_week'].replace({7: 0})\n",
    "load_features_tx[load_features_tx['datetime'].dt.hour == 0][['datetime', 'day_of_week', 'day_of_week_mod']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holiday Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holiday Handling\n",
    "# Need to go back and handle surrounding days\n",
    "load_features_tx['day_of_week'] = load_features_tx['datetime'].dt.weekday\n",
    "\n",
    "# Convert 'datetime' to date\n",
    "load_features_tx['date'] = load_features_tx['datetime'].dt.date\n",
    "load_features_tx['day_of_week_modified'] = load_features_tx['day_of_week']\n",
    "\n",
    "# Step 2: Handle holidays and surrounding days\n",
    "# Assuming 'datetime' column is of datetime type\n",
    "holidays = {\n",
    "    'new_years_day': {'month': 1, 'day': 1, 'before': (12, 31), 'friday_to_saturday': True},\n",
    "    'memorial_day': {'month': 5, 'day_last_monday': True, 'after': (5, 'last_monday')},\n",
    "    'independence_day': {'month': 7, 'day': 4, 'before': (7, 3)},\n",
    "    'labor_day': {'month': 9, 'day_first_monday': True, 'after': (9, 'first_monday')},\n",
    "    'thanksgiving_day': {'month': 11, 'day_fourth_thursday': True, 'before': (11, 'fourth_thursday'), 'after': (11, 'fourth_thursday')},\n",
    "    'christmas_day': {'month': 12, 'day': 25, 'before': (12, 24), 'after': (12, 26)}\n",
    "}\n",
    "\n",
    "# Helper functions to identify holidays\n",
    "def is_holiday(date, holiday_info):\n",
    "    if 'day' in holiday_info and date.month == holiday_info['month'] and date.day == holiday_info['day']:\n",
    "        return True\n",
    "    if 'before' in holiday_info and date.month == holiday_info['before'][0] and date.day == holiday_info['before'][1]:\n",
    "        return True\n",
    "    if 'after' in holiday_info and date.month == holiday_info['after'][0] and date.day == holiday_info['after'][1]:\n",
    "        return True\n",
    "    # Memorial Day\n",
    "    if 'day_last_monday' in holiday_info and date.month == holiday_info['month'] and date.weekday() == 0:\n",
    "        last_monday = max([d for d in pd.date_range(start=f'{date.year}-{date.month}-01', end=pd.Timestamp(date.year, date.month, 1) + pd.offsets.MonthEnd(0)) if d.weekday() == 0])\n",
    "        return date == last_monday\n",
    "    # Day after memorial day\n",
    "    if 'after' in holiday_info and date.month == holiday_info['month'] and holiday_info['after'][1] == 'last_monday' and date.weekday() == 1:\n",
    "        last_monday = max([d for d in pd.date_range(start=f'{date.year}-{date.month}-01', end=pd.Timestamp(date.year, date.month, 1) + pd.offsets.MonthEnd(0)) if d.weekday() == 0])\n",
    "        return date == last_monday + 1 * pd.DateOffset(days=1)\n",
    "    # Labor Day\n",
    "    if 'day_first_monday' in holiday_info and date.month == holiday_info['month'] and date.weekday() == 0:\n",
    "        first_monday = min([d for d in pd.date_range(start=f'{date.year}-{date.month}-01', end=f'{date.year}-{date.month}-07') if d.weekday() == 0])\n",
    "        return date == first_monday   \n",
    "    # Day after labor day\n",
    "    if 'after' in holiday_info and date.month == holiday_info['month'] and holiday_info['after'][1] == 'first_monday' and date.weekday() == 1:\n",
    "        first_monday = min([d for d in pd.date_range(start=f'{date.year}-{date.month}-01', end=f'{date.year}-{date.month}-07') if d.weekday() == 0])\n",
    "        return date == first_monday + 1 * pd.DateOffset(days=1)\n",
    "    # Day before Thanksgiving day\n",
    "    if 'before' in holiday_info and date.month == holiday_info['month'] and holiday_info['before'][1] == 'fourth_thursday' and date.weekday() == 2:\n",
    "        fourth_thursday = [d for d in pd.date_range(start=f'{date.year}-{date.month}-01', end=pd.Timestamp(date.year, date.month, 1) + pd.offsets.MonthEnd(0)) if d.weekday() == 3][3]\n",
    "        return date == fourth_thursday - 1 * pd.DateOffset(days=1)\n",
    "    # Thanksgiving Day\n",
    "    if 'day_fourth_thursday' in holiday_info and date.month == holiday_info['month'] and date.weekday() == 3:\n",
    "        fourth_thursday = [d for d in pd.date_range(start=f'{date.year}-{date.month}-01', end=pd.Timestamp(date.year, date.month, 1) + pd.offsets.MonthEnd(0)) if d.weekday() == 3][3]\n",
    "        return date == fourth_thursday\n",
    "    # Day after Thanksgiving day\n",
    "    if 'after' in holiday_info and date.month == holiday_info['month'] and holiday_info['after'][1] == 'fourth_thursday' and date.weekday() == 4:\n",
    "        fourth_thursday = [d for d in pd.date_range(start=f'{date.year}-{date.month}-01', end=pd.Timestamp(date.year, date.month, 1) + pd.offsets.MonthEnd(0)) if d.weekday() == 3][3]\n",
    "        return date == fourth_thursday + 1 * pd.DateOffset(days=1) \n",
    "    return False\n",
    "\n",
    "# Modify the 'day_of_week_modified' based on holidays\n",
    "for index, row in load_features_tx.iterrows():\n",
    "    date = row['datetime']\n",
    "    for holiday, info in holidays.items():\n",
    "        if is_holiday(date, info):\n",
    "            if holiday in ('new_years_day', 'independence_day', 'christmas_day'):\n",
    "                #Exact Holday\n",
    "                if date.day == info['day']:\n",
    "                    # If holiday is on Friday, move to Saturday\n",
    "                    if date.weekday() == 4:  # Friday\n",
    "                        load_features_tx.at[index, 'day_of_week_modified'] = 5  # Saturday\n",
    "                    else:\n",
    "                        load_features_tx.at[index, 'day_of_week_modified'] = 6  # Sunday\n",
    "                # Handle day before independence day\n",
    "                elif holiday == 'independence_day' and 'before' in info:\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 4 # Friday\n",
    "                # Day before or after holiday\n",
    "                else:\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 5 # Saturday\n",
    "            elif holiday in ['memorial_day', 'labor_day', 'thanksgiving_day']:\n",
    "                \n",
    "                #Memorial Day\n",
    "                if holiday == 'memorial_day' and date.weekday() == 0:\n",
    "                    # print(date, holiday)\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 5 # Saturday\n",
    "                # Day after memorial day \n",
    "                elif holiday == 'memorial_day' and date.weekday() == 1:\n",
    "                    # print(date, holiday)\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 0 # Monday\n",
    "                #Labor Day\n",
    "                elif holiday == 'labor_day' and date.weekday() == 0:\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 5 # Saturday\n",
    "                # Day after labor day\n",
    "                elif holiday == 'labor_day' and date.weekday() == 1:\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 3 # Thursday\n",
    "                # Day before Thanksgiving day\n",
    "                elif holiday == 'thanksgiving_day' and date.weekday() == 2:\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 0 # Monday\n",
    "                #Thanksgiving Day\n",
    "                elif holiday == 'thanksgiving_day' and date.weekday() == 3:\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 5 # Saturday\n",
    "                # Day after Thanksgiving day\n",
    "                elif holiday == 'thanksgiving_day' and date.weekday() == 4:\n",
    "                    load_features_tx.at[index, 'day_of_week_modified'] = 5 # Saturday\n",
    "\n",
    "            # elif 'before' in info or 'after' in info:\n",
    "            #     load_features_tx.at[index, 'day_of_week_modified'] = 6  # Saturday\n",
    "\n",
    "# Convert Wednesdays to Tuesdays\n",
    "load_features_tx['day_of_week_modified'] = load_features_tx['day_of_week_modified'].replace({2: 1})  # 2=Wednesday, 1=Tuesday\n",
    "\n",
    "# Filter rows where the date matches the holiday list (ignoring the year)\n",
    "holiday_examples = load_features_tx[load_features_tx['day_of_week'] != load_features_tx['day_of_week_modified']]\n",
    "\n",
    "# Further filter to only show rows where the hour is 0 and not Tuesday\n",
    "holiday_examples = holiday_examples[(holiday_examples['datetime'].dt.hour == 0) & (holiday_examples['day_of_week_modified'] != 1)]\n",
    "\n",
    "# Display one example hour for each holiday\n",
    "pd.set_option('display.max_rows', None)  \n",
    "print(holiday_examples[['datetime', 'day_of_week', 'day_of_week_modified']].tail(25))\n",
    "pd.set_option('display.max_rows', 10) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic Temporal Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform month, day_of_year, and hour to cyclic features\n",
    "load_features_tx['month_sin'] = np.sin(2 * np.pi * load_features_tx['month'] / 12)\n",
    "load_features_tx['month_cos'] = np.cos(2 * np.pi * load_features_tx['month'] / 12)\n",
    "\n",
    "load_features_tx['day_of_year_sin'] = np.sin(2 * np.pi * load_features_tx['day_of_year'] / 365)\n",
    "load_features_tx['day_of_year_cos'] = np.cos(2 * np.pi * load_features_tx['day_of_year'] / 365)\n",
    "\n",
    "load_features_tx['day_of_week_sin'] = np.sin(2 * np.pi * load_features_tx['day_of_week_modified'] / 7)\n",
    "load_features_tx['day_of_week_cos'] = np.cos(2 * np.pi * load_features_tx['day_of_week_modified'] / 7)\n",
    "\n",
    "load_features_tx['hour_sin'] = np.sin(2 * np.pi * load_features_tx['hour'] / 24)\n",
    "load_features_tx['hour_cos'] = np.cos(2 * np.pi * load_features_tx['hour'] / 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_features_slim = load_features_tx[['datetime', 'total_system_load', 'total_system_customers', \n",
    "                                    # 'hdd_sensitivity', 'cdd_sensitivity'\n",
    "                                    'temperature_avg', 'temp_1h_ago', 'temp_2h_ago', 'temp_3h_ago', 'avg_temp_last_24h',\n",
    "                                    'hour', 'day_of_week_modified', 'month'\n",
    "                                    ]]\n",
    "\n",
    "# Add polynomial and cross effect terms\n",
    "load_features_slim = load_features_slim.copy()  # Avoid SettingWithCopyWarning\n",
    "load_features_slim['temperature_avg^2'] = load_features_slim['temperature_avg'] ** 2\n",
    "load_features_slim['temperature_avg^3'] = load_features_slim['temperature_avg'] ** 3\n",
    "load_features_slim['temp_1h_ago^2'] = load_features_slim['temp_1h_ago'] ** 2\n",
    "load_features_slim['temp_1h_ago^3'] = load_features_slim['temp_1h_ago'] ** 3\n",
    "load_features_slim['temp_2h_ago^2'] = load_features_slim['temp_2h_ago'] ** 2\n",
    "load_features_slim['temp_2h_ago^3'] = load_features_slim['temp_2h_ago'] ** 3\n",
    "load_features_slim['temp_3h_ago^2'] = load_features_slim['temp_3h_ago'] ** 2\n",
    "load_features_slim['temp_3h_ago^3'] = load_features_slim['temp_3h_ago'] ** 3\n",
    "load_features_slim['avg_temp_last_24h^2'] = load_features_slim['avg_temp_last_24h'] ** 2\n",
    "load_features_slim['avg_temp_last_24h^3'] = load_features_slim['avg_temp_last_24h'] ** 3\n",
    "\n",
    "# Function to add cross terms for indicator variables\n",
    "def add_cross_terms(df, indicator_columns, numeric_columns):\n",
    "    cross_term_data = []\n",
    "    for ind_col in indicator_columns:\n",
    "        for num_col in numeric_columns:\n",
    "            cross_term_data.append(df[ind_col] * df[num_col])\n",
    "            cross_term_data[-1].name = f'{ind_col}*{num_col}'\n",
    "    return pd.concat([df] + cross_term_data, axis=1)\n",
    "\n",
    "# Convert 'month' and 'day_of_week_modified' to indicator variables\n",
    "hour_dummies = pd.get_dummies(load_features_slim['hour'], prefix='hour', drop_first=False)\n",
    "month_dummies = pd.get_dummies(load_features_slim['month'], prefix='month', drop_first=False)\n",
    "day_of_week_dummies = pd.get_dummies(load_features_slim['day_of_week_modified'], prefix='weekday', drop_first=False)\n",
    "\n",
    "# Concatenate the dummies with the original dataframe\n",
    "load_features_slim = pd.concat([load_features_slim, month_dummies, day_of_week_dummies, hour_dummies], axis=1)\n",
    "\n",
    "# Get list of indicator and numeric columns\n",
    "indicator_columns = month_dummies.columns.tolist() + hour_dummies.columns.tolist()\n",
    "numeric_columns = ['temperature_avg', 'temperature_avg^2', 'temperature_avg^3', \n",
    "                   'temp_1h_ago', 'temp_1h_ago^2', 'temp_1h_ago^3',\n",
    "                   'temp_2h_ago', 'temp_2h_ago^2', 'temp_2h_ago^3',\n",
    "                   'temp_3h_ago', 'temp_3h_ago^2', 'temp_3h_ago^3',\n",
    "                   'avg_temp_last_24h', 'avg_temp_last_24h^2', 'avg_temp_last_24h^3'\n",
    "]\n",
    "\n",
    "# Add cross terms for month and hour\n",
    "load_features_slim = add_cross_terms(load_features_slim, indicator_columns, numeric_columns)\n",
    "\n",
    "# Add cross terms for day of week and hour\n",
    "load_features_slim = add_cross_terms(load_features_slim, day_of_week_dummies.columns.tolist(), month_dummies.columns.tolist())\n",
    "\n",
    "#Drop columns that are not needed\n",
    "load_features_slim.drop(columns=['hour', 'day_of_week_modified', 'month'], inplace=True)\n",
    "\n",
    "load_features_slim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Filter\n",
    "Hong 2014 uses only 2 years of training data. So we'll test on the most recent year and use the previous 2 years to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to last 3 years\n",
    "start_index = int(len(load_features_slim) - 365 * 24*3)  # Assuming data is hourly and each day has 24 hours\n",
    "load_features_slim_time = load_features_slim.iloc[start_index:]\n",
    "load_features_slim_time.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X (features) and y (target)\n",
    "X = load_features_slim_time.drop(columns=['datetime', 'total_system_load'])\n",
    "y = load_features_slim_time['total_system_load']\n",
    "\n",
    "# Split data into training and validation sets (most recent year for validation)\n",
    "# Assuming the data is in chronological order, the last year will be used for validation\n",
    "split_index = int(len(X) - 365 * 24)  # Assuming data is hourly and each day has 24 hours\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_test.shape}, y_val shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Set Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Multiple Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "mape = np.mean(np.abs((y_train - y_pred) / y_train)) * 100\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Add back in the datetime for plotting\n",
    "X_train_with_datetime = X_train.copy()\n",
    "X_train_with_datetime['datetime'] = load_features_slim_time.loc[X_train.index, 'datetime']\n",
    "\n",
    "\n",
    "# Plot y_pred vs y_val over time using Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=X_train_with_datetime['datetime'], y=y_train, mode='lines', name='Actual Load', line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=X_train_with_datetime['datetime'], y=y_pred, mode='lines', name='Predicted Load', line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training Error:Predicted vs Actual Total System Load Over Time',\n",
    "    xaxis_title='Datetime',\n",
    "    yaxis_title='Total System Load',\n",
    "    legend=dict(x=0, y=1),\n",
    "    xaxis=dict(rangeslider=dict(visible=True)),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_\n",
    "})\n",
    "print(\"\\nCoefficients of the model:\")\n",
    "print(coefficients.sort_values('Coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Add back in the datetime for plotting\n",
    "X_test_with_datetime = X_test.copy()\n",
    "X_test_with_datetime['datetime'] = load_features_slim_time.loc[X_test.index, 'datetime']\n",
    "\n",
    "\n",
    "# Plot y_pred vs y_val over time using Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=X_test_with_datetime['datetime'], y=y_test, mode='lines', name='Actual Load', line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=X_test_with_datetime['datetime'], y=y_pred, mode='lines', name='Predicted Load', line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Predicted vs Actual Total System Load Over Time',\n",
    "    xaxis_title='Datetime',\n",
    "    yaxis_title='Total System Load',\n",
    "    legend=dict(x=0, y=1),\n",
    "    xaxis=dict(rangeslider=dict(visible=True)),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hong 2014 Reduced Features Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we experimented with training a NN on all 670 constructed features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit to last 3 years\n",
    "start_index = int(len(load_features_slim) - 365 * 24*3)  # Assuming data is hourly and each day has 24 hours\n",
    "load_features_slim_time = load_features_slim.iloc[start_index:]\n",
    "load_features_slim_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define X (features) and y (target)\n",
    "X = load_features_slim_time.drop(columns=['datetime', 'total_system_load'])\n",
    "y = load_features_slim_time['total_system_load']\n",
    "\n",
    "# Split data into training and validation sets (most recent year for validation)\n",
    "# Assuming the data is in chronological order, the last year will be used for validation\n",
    "split_index = int(len(X) - 365 * 24)  # Assuming data is hourly and each day has 24 hours\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_test.shape}, y_val shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, input_dim=X.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Dropout(0.3),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Dropout(0.2),\n",
    "    \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Dropout(0.1),\n",
    "    \n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Step 2: Compile the Model\n",
    "# Lets try a faster learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.02), loss='mse', metrics=['mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using the updated train and validation sets\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "    ]\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=64, callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "y_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print shapes and ranges\n",
    "print(\"Original y_train range:\", y_train.min(), y_train.max())\n",
    "\n",
    "# Scale and check\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "print(\"Scaled y_train range:\", y_train_scaled.min(), y_train_scaled.max())\n",
    "print(\"Scaled y_train mean:\", y_train_scaled.mean())\n",
    "print(\"Scaled y_train std:\", y_train_scaled.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train_scaled shape:\", y_train_scaled.shape)\n",
    "\n",
    "# Also check the ranges\n",
    "print(\"\\nScaled ranges:\")\n",
    "print(\"X_train_scaled min/max:\", X_train_scaled.min(), X_train_scaled.max())\n",
    "print(\"y_train_scaled min/max:\", y_train_scaled.min(), y_train_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = train_model(model, X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled)\n",
    "# history = train_model(model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5: Error Analysis - Visualize Predictions vs Actuals\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Reverse the normalization of the target variable if needed\n",
    "# y_val_actual = y_scaler.inverse_transform(y_val)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Create a DataFrame to hold actual vs predicted values\n",
    "error_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
    "\n",
    "# Add back in the datetime for plotting\n",
    "# X_test_with_datetime = test_df_part2.copy()\n",
    "error_df['datetime'] = load_features_slim_time.loc[error_df.index, 'datetime']\n",
    "\n",
    "# Plot Actual vs Predicted using Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=error_df['datetime'], y=error_df['Actual'], mode='lines', name='Actual Load'))\n",
    "fig.add_trace(go.Scatter(x=error_df['datetime'], y=error_df['Predicted'], mode='lines', name='Predicted Load'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Actual vs Predicted Load Over Time',\n",
    "    xaxis_title='Datetime',\n",
    "    yaxis_title='Load',\n",
    "    legend=dict(x=0, y=1),\n",
    "    xaxis=dict(rangeslider=dict(visible=True)),\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate MAPE for each point\n",
    "error_df['MAPE'] = np.abs((error_df['Actual'] - error_df['Predicted']) / error_df['Actual']) * 100\n",
    "\n",
    "# Create MAPE plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=error_df['datetime'], \n",
    "    y=error_df['MAPE'], \n",
    "    mode='lines', \n",
    "    name='MAPE'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='MAPE Over Time',\n",
    "    xaxis_title='Datetime',\n",
    "    yaxis_title='MAPE (%)',\n",
    "    template='plotly_white',\n",
    "    showlegend=True,\n",
    "    xaxis=dict(rangeslider=dict(visible=False))\n",
    ")\n",
    "\n",
    "# Add a line for average MAPE\n",
    "avg_mape = error_df['MAPE'].mean()\n",
    "fig.add_hline(y=avg_mape, line_dash=\"dash\", line_color=\"red\", \n",
    "              annotation_text=f\"Avg MAPE: {avg_mape:.2f}%\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print summary statistics of MAPE\n",
    "print(\"\\nMAPE Statistics:\")\n",
    "print(error_df['MAPE'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Training a FCNN with 670 features, we obtain a MAPE of ~17.3%, well above our MAPE from linear regression. Let's transtion to training a FCNN with our base features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Period Temporal Features Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "core_features = ['datetime', 'total_system_load', 'total_system_customers']\n",
    "time_features = ['month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week_sin', 'day_of_week_cos', 'hour_sin', 'hour_cos']\n",
    "temp_features = ['temperature_avg', 'temp_1h_ago', 'temp_2h_ago', 'temp_3h_ago', 'avg_temp_last_24h']\n",
    "\n",
    "load_features_nn = load_features_tx[core_features + time_features + temp_features]\n",
    "print(load_features_nn.shape)\n",
    "load_features_nn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_features_nn.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train/ Validation/ Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split our data into 2 years of training data, one year of validation data to choose the optimal parameters, and one year of test data. Prior to running the model on test data, we will retrain the model on the two years preceeding the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure your data is sorted by datetime\n",
    "load_features_nn = load_features_nn.sort_values('datetime')\n",
    "\n",
    "# Convert the 'datetime' column to pandas datetime format if it's not already\n",
    "load_features_nn['datetime'] = pd.to_datetime(load_features_nn['datetime'])\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = load_features_nn.drop(columns=['datetime', 'total_system_load'])\n",
    "y = load_features_nn['total_system_load']\n",
    "\n",
    "# Step 1: Hyperparameter Tuning\n",
    "# Split data by specific date ranges\n",
    "train_df_part1 = load_features_nn[(load_features_nn['datetime'] >= '2020-11-01') & (load_features_nn['datetime'] < '2022-11-01')]\n",
    "val_df_part1 = load_features_nn[(load_features_nn['datetime'] >= '2022-11-01') & (load_features_nn['datetime'] < '2023-11-01')]\n",
    "\n",
    "X_train_part1 = train_df_part1.drop(columns=['datetime', 'total_system_load'])\n",
    "y_train_part1 = train_df_part1['total_system_load']\n",
    "X_val_part1 = val_df_part1.drop(columns=['datetime', 'total_system_load'])\n",
    "y_val_part1 = val_df_part1['total_system_load']\n",
    "\n",
    "print(\"Part 1 - Hyperparameter Tuning:\")\n",
    "print(f\"X_train_part1 shape: {X_train_part1.shape}, y_train_part1 shape: {y_train_part1.shape}\")\n",
    "print(f\"X_val_part1 shape: {X_val_part1.shape}, y_val_part1 shape: {y_val_part1.shape}\")\n",
    "\n",
    "# Scale the features and target\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Fit and transform the training set\n",
    "X_train_part1_scaled = scaler_X.fit_transform(X_train_part1)\n",
    "y_train_part1_scaled = scaler_y.fit_transform(y_train_part1.values.reshape(-1, 1))\n",
    "\n",
    "# Transform the validation set using the same scaler\n",
    "X_val_part1_scaled = scaler_X.transform(X_val_part1)\n",
    "y_val_part1_scaled = scaler_y.transform(y_val_part1.values.reshape(-1, 1))\n",
    "\n",
    "# Part 2: Final Training and Testing\n",
    "train_df_part2 = load_features_nn[(load_features_nn['datetime'] >= '2021-11-01') & (load_features_nn['datetime'] < '2023-11-01')]\n",
    "test_df_part2 = load_features_nn[(load_features_nn['datetime'] >= '2023-11-01') & (load_features_nn['datetime'] < '2024-11-01')]\n",
    "\n",
    "X_train_part2 = train_df_part2.drop(columns=['datetime', 'total_system_load'])\n",
    "y_train_part2 = train_df_part2['total_system_load']\n",
    "X_test_part2 = test_df_part2.drop(columns=['datetime', 'total_system_load'])\n",
    "y_test_part2 = test_df_part2['total_system_load']\n",
    "\n",
    "print(\"\\nPart 2 - Final Training and Testing:\")\n",
    "print(f\"X_train_part2 shape: {X_train_part2.shape}, y_train_part2 shape: {y_train_part2.shape}\")\n",
    "print(f\"X_test_part2 shape: {X_test_part2.shape}, y_test_part2 shape: {y_test_part2.shape}\")\n",
    "\n",
    "# Scale the features and target using the same scalers from Part 1\n",
    "X_train_part2_scaled = scaler_X.transform(X_train_part2)\n",
    "y_train_part2_scaled = scaler_y.transform(y_train_part2.values.reshape(-1, 1)) # should I flatten this?\n",
    "\n",
    "X_test_part2_scaled = scaler_X.transform(X_test_part2)\n",
    "y_test_part2_scaled = scaler_y.transform(y_test_part2.values.reshape(-1, 1)) #Should I flatten this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shapes After Scaling:\")\n",
    "print(f\"X_train_part1_scaled: {X_train_part1_scaled.shape}, y_train_part1_scaled: {y_train_part1_scaled.shape}\")\n",
    "print(f\"X_val_part1_scaled: {X_val_part1_scaled.shape}, y_val_part1_scaled: {y_val_part1_scaled.shape}\")\n",
    "print(f\"X_train_part2_scaled: {X_train_part2_scaled.shape}, y_train_part2_scaled: {y_train_part2_scaled.shape}\")\n",
    "print(f\"X_test_part2_scaled: {X_test_part2_scaled.shape}, y_test_part2_scaled: {y_test_part2_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#Print Scaled MAPE every epoch\n",
    "class RealTimeMAPECallback(Callback):\n",
    "    def __init__(self, X_val, y_val, y_scaler):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Get predictions on validation data\n",
    "        y_pred_scaled = self.model.predict(self.X_val)\n",
    "        \n",
    "        # Inverse transform predictions and actuals\n",
    "        y_pred = self.y_scaler.inverse_transform(y_pred_scaled)\n",
    "        y_true = self.y_scaler.inverse_transform(self.y_val)\n",
    "        \n",
    "        # Calculate MAPE\n",
    "        mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "        print(f\"Epoch {epoch + 1} - Real-time MAPE on validation data: {mape:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, input_dim=X.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Dropout(0.2),\n",
    "    \n",
    "#     Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.2),\n",
    "    \n",
    "#     Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.2),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Dropout(0.1),\n",
    "    \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Dropout(0.1),\n",
    "    \n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Step 2: Compile the Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Using the updated train and validation sets\n",
    "def train_model(model, X_train, y_train, X_val, y_val, y_scaler):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6),\n",
    "        RealTimeMAPECallback(X_val, y_val, y_scaler)\n",
    "    ]\n",
    "    history = model.fit(X_train, \n",
    "                        y_train, \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        epochs=100, \n",
    "                        batch_size=64,  # Power of 2 near sqrt(n_samples)\n",
    "                        callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = train_model(model, X_train_part2_scaled, y_train_part2_scaled, X_test_part2_scaled, y_test_part2_scaled, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform cross validation to determine the optimal hyperparameters. In order to optimize the batch size, we needed to modify the keras tuner class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predefined layer configurations\n",
    "layer_options = [\n",
    "    [256, 128, 16],\n",
    "    [128, 64, 32],\n",
    "    [64, 32, 16],\n",
    "    [32, 16, 8]\n",
    "]\n",
    "\n",
    "dropout_options = [\n",
    "    [None, None, None], \n",
    "    [0.2, 0.2, 0.1], \n",
    "    [0.3, 0.2, 0.1]\n",
    "]\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        # Define layers using hyperparameters\n",
    "        layer_index = hp.Choice('layers', [0, 1, 2, 3])  # 0: [256, 128, 64], 1: [256, 256, 128], 2: [128, 64, 32]\n",
    "        layers_config = layer_options[layer_index]\n",
    "        \n",
    "        # Let's not use dropout now since we are using batch normalization\n",
    "        # dropout_index = hp.Choice('dropout_rates', [0, 1, 2])\n",
    "        # dropout_rates = dropout_options[dropout_index]\n",
    "\n",
    "        learning_rate = hp.Choice('learning_rate', [0.0005, 0.001, 0.005, 0.01, 0.02])\n",
    "        # l2_reg = hp.Choice('l2_reg', [0.001, 0.005, 0.01])\n",
    "\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        for i, units in enumerate(layers_config):\n",
    "            model.add(layers.Dense(units, activation='relu'\n",
    "                                   # , kernel_regularizer=l2(l2_reg) # Remove because we have batch norm\n",
    "                                  ))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            # if dropout_rates[i]:\n",
    "            #     model.add(layers.Dropout(dropout_rates[i]))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(layers.Dense(1, activation='linear'))\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=['mae', 'mape'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        # Include batch_size as a tunable hyperparameter during training\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [32, 64, 128]),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to perform hyperparameter tuning\n",
    "def perform_hyperparameter_tuning(X_train, y_train, X_val, y_val):\n",
    "    global tuner\n",
    "    tuner = kt.RandomSearch(\n",
    "        MyHyperModel(),\n",
    "        objective='val_loss',\n",
    "        # max_epochs=100,\n",
    "        max_trials=30,\n",
    "        # factor=3,\n",
    "        directory='random_search', #'hyperband_limited_search',\n",
    "        project_name='load_forecasting_with_random_search',\n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    stop_early = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Perform the search using the custom validation set\n",
    "    tuner.search(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=[stop_early],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Get the best hyperparameters\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return best_hps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_hps = perform_hyperparameter_tuning(\n",
    "    X_train_part1_scaled, y_train_part1_scaled, \n",
    "    X_val_part1_scaled, y_val_part1_scaled\n",
    ")\n",
    "print(f\"Best hyperparameters: {best_hps.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_hps.values['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_all_trials(tuner):\n",
    "    # Extract all trials\n",
    "    trials = tuner.oracle.trials.values()\n",
    "    \n",
    "    # Prepare a list to store the results\n",
    "    trial_data = []\n",
    "    \n",
    "    # Loop through each trial and extract relevant information\n",
    "    for trial in trials:\n",
    "        # Get the history and extract the last step (epoch) number\n",
    "        history = trial.metrics.get_history('val_loss')\n",
    "        epochs_run = history[-1].step if history else 'N/A'\n",
    "        \n",
    "        trial_info = {\n",
    "            'Trial ID': trial.trial_id,\n",
    "            'Layers': trial.hyperparameters.get('layers'),\n",
    "            # 'Dropout Rates': trial.hyperparameters.get('dropout_rates'),\n",
    "            # 'Activation': trial.hyperparameters.get('activation'),\n",
    "            'Learning Rate': trial.hyperparameters.get('learning_rate'),\n",
    "            # 'L2 Regularization': trial.hyperparameters.get('l2_reg'),\n",
    "            'Batch Size': trial.hyperparameters.get('batch_size'),\n",
    "            'Num epochs': epochs_run,\n",
    "            'Validation Loss': trial.score\n",
    "        }\n",
    "        trial_data.append(trial_info)\n",
    "    \n",
    "    # Convert the results to a pandas DataFrame for better visualization\n",
    "    df = pd.DataFrame(trial_data)\n",
    "    \n",
    "    # Sort by validation loss (lower is better)\n",
    "    df.sort_values(by='Validation Loss', ascending=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Call the function to display all the trials\n",
    "trials_df = display_all_trials(tuner)\n",
    "\n",
    "pd.set_option('display.max_rows', None)  \n",
    "print(trials_df)\n",
    "pd.set_option('display.max_rows', 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials = tuner.oracle.trials.values()\n",
    "for trial in trials:\n",
    "    print(trial.metrics.get_history('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Continue training best model\n",
    "\n",
    "def create_model(input_dim, layers, learning_rate):\n",
    "    model = Sequential([\n",
    "        Dense(layers[0], input_dim=input_dim, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(layers[1], activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(layers[2], activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mae', 'mape']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, y_scaler, batch_size=64, epochs=100):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6),\n",
    "        RealTimeMAPECallback(X_val, y_val, y_scaler)\n",
    "    ]\n",
    "    return model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n",
    "model = create_model(\n",
    "    input_dim=X_train_part1_scaled.shape[1],\n",
    "    layers=layer_options[best_hps.get('layers')],\n",
    "    learning_rate=best_hps.get('learning_rate')\n",
    ")\n",
    "\n",
    "history = train_model(\n",
    "    model, \n",
    "    X_train_part1_scaled, \n",
    "    y_train_part1_scaled, \n",
    "    X_val_part1_scaled, \n",
    "    y_val_part1_scaled, \n",
    "    y_scaler,\n",
    "    batch_size=best_hps.get('batch_size')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain on 2022-2023 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters previous determined, let's retrain on 2022-2023 data to build a model that we will use to predict on 2024 data. This ensures the same recency relationship between train and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use them like this:\n",
    "model = create_model(\n",
    "    input_dim=X_train_part2_scaled.shape[1],\n",
    "    layers=layer_options[0], #layer_options[best_hps.get('layers')],\n",
    "    learning_rate=0.02 #best_hps.get('learning_rate')\n",
    ")\n",
    "\n",
    "history = train_model(\n",
    "    model, \n",
    "    X_train_part2_scaled, \n",
    "    y_train_part2_scaled, \n",
    "    X_test_part2_scaled, \n",
    "    y_test_part2_scaled, \n",
    "    y_scaler,\n",
    "    batch_size=64 # best_hps.get('batch_size')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Visualize the Metrics\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot MAPE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mape'], label='Training MAPE')\n",
    "plt.plot(history.history['val_mape'], label='Validation MAPE')\n",
    "plt.title('Model MAPE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Visualize the Metrics with Plotly\n",
    "# Plot the training and validation loss\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for loss\n",
    "fig.add_trace(go.Scatter(y=history.history['loss'], mode='lines', name='Training Loss'))\n",
    "fig.add_trace(go.Scatter(y=history.history['val_loss'], mode='lines', name='Validation Loss'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Plot the MAPE\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for MAPE\n",
    "fig.add_trace(go.Scatter(y=history.history['mape'], mode='lines', name='Training MAPE'))\n",
    "fig.add_trace(go.Scatter(y=history.history['val_mape'], mode='lines', name='Validation MAPE'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model MAPE',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='MAPE (%)',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_test_part2_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_pred = y_pred.reshape(-1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5: Error Analysis - Visualize Predictions vs Actuals\n",
    "y_pred_scaled = model.predict(X_test_part2_scaled)\n",
    "\n",
    "# Reverse the normalization of the target variable if needed\n",
    "# y_val_actual = y_scaler.inverse_transform(y_val)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Create a DataFrame to hold actual vs predicted values\n",
    "error_df = pd.DataFrame({'Actual': y_test_part2, 'Predicted': y_pred.flatten()})\n",
    "\n",
    "# Add back in the datetime for plotting\n",
    "# X_test_with_datetime = test_df_part2.copy()\n",
    "error_df['datetime'] = test_df_part2.loc[error_df.index, 'datetime']\n",
    "\n",
    "# Plot Actual vs Predicted using Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=error_df['datetime'], y=error_df['Actual'], mode='lines', name='Actual Load'))\n",
    "fig.add_trace(go.Scatter(x=error_df['datetime'], y=error_df['Predicted'], mode='lines', name='Predicted Load'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Actual vs Predicted Load Over Time',\n",
    "    xaxis_title='Datetime',\n",
    "    yaxis_title='Load',\n",
    "    legend=dict(x=0, y=1),\n",
    "    xaxis=dict(rangeslider=dict(visible=True)),\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate MAPE for each point\n",
    "error_df['MAPE'] = np.abs((error_df['Actual'] - error_df['Predicted']) / error_df['Actual']) * 100\n",
    "\n",
    "# Create MAPE plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=error_df['datetime'], \n",
    "    y=error_df['MAPE'], \n",
    "    mode='lines', \n",
    "    name='MAPE'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='MAPE Over Time',\n",
    "    xaxis_title='Datetime',\n",
    "    yaxis_title='MAPE (%)',\n",
    "    template='plotly_white',\n",
    "    showlegend=True,\n",
    "    xaxis=dict(rangeslider=dict(visible=False))\n",
    ")\n",
    "\n",
    "# Add a line for average MAPE\n",
    "avg_mape = error_df['MAPE'].mean()\n",
    "fig.add_hline(y=avg_mape, line_dash=\"dash\", line_color=\"red\", \n",
    "              annotation_text=f\"Avg MAPE: {avg_mape:.2f}%\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print summary statistics of MAPE\n",
    "print(\"\\nMAPE Statistics:\")\n",
    "print(error_df['MAPE'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we observe a significantly lower MAPE of ~4.35 that beats both the previous 670 NN model and the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
